"""
ë°ì´í„° í¬ë¡¤ë§ ëª¨ë“ˆ
Amaranth ê·¸ë£¹ì›¨ì–´ì—ì„œ ì¢…ê²°ëœ ë§¤ì¶œ/ë§¤ì… í’ˆì˜ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

from tarfile import data_filter
import time
import re
from datetime import datetime, timedelta
from typing import List, Tuple, Dict, Any
import pandas as pd
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from bs4 import BeautifulSoup
import logging

logger = logging.getLogger(__name__)

def navigate_to_handover_document_list(driver):
    """
    1. 'ì „ìê²°ì¬' ë©”ë‰´ í´ë¦­
    2. 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ í´ë¦­ì„ í†µí•´ ìµœì¢… ëª©ì ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.
    """
    
    # 1. 'ì „ìê²°ì¬' ë©”ë‰´ í´ë¦­ (í˜ì´ì§€ ì´ë™)
    logger.info("1ë‹¨ê³„: ğŸ” 'ì „ìê²°ì¬' ë©”ë‰´ í´ë¦­ ì‹œë„ ì¤‘...")
    try:
        # ê°€ì¥ ì•ˆì •ì ì¸ í…ìŠ¤íŠ¸ ê¸°ë°˜ XPath ì‚¬ìš©
        XPATH_ELECTRONIC_APPROVAL = "//span[text()='ì „ìê²°ì¬']"
        
        WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, XPATH_ELECTRONIC_APPROVAL))
        ).click()
        
        logger.info("âœ… 'ì „ìê²°ì¬' ë©”ë‰´ í´ë¦­ ì„±ê³µ. í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...")
        
    except TimeoutException:
        logger.error("âŒ 1ë‹¨ê³„: 'ì „ìê²°ì¬' ë©”ë‰´ë¥¼ ì°¾ê±°ë‚˜ í´ë¦­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Timeout)")
        return False
    except Exception as e:
        logger.error(f"âŒ 1ë‹¨ê³„: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
    
    # --- í˜ì´ì§€ ì´ë™ í›„ ë¡œë”© ëŒ€ê¸° ë° 2ë‹¨ê³„ í´ë¦­ ì‹œì‘ ---

    logger.info("2ë‹¨ê³„: ğŸ” 'ì¸ìˆ˜ì¸ê³„' ë©”ë‰´ í™•ì¥ ë° 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' í´ë¦­ ì‹œë„ ì¤‘...")
    try:
        # 1. í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°: ìƒˆë¡œìš´ í˜ì´ì§€ì—ì„œ ê³ ìœ í•œ ìš”ì†Œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        XPATH_APPROVAL_CONTENT_AREA = "//div[@id='sideLnb']"
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.XPATH, XPATH_APPROVAL_CONTENT_AREA))
        )
        logger.info("âœ… ì „ìê²°ì¬ í˜ì´ì§€ ë‚´ë¶€ ìš”ì†Œ ë¡œë”© ì™„ë£Œ í™•ì¸.")
        
        # ì¶”ê°€ ì•ˆì •í™” ì‹œê°„
        time.sleep(2)
        
        # 2. 'ì¸ìˆ˜ì¸ê³„' ìƒìœ„ ë©”ë‰´ ì°¾ê¸° ë° í´ë¦­ (í•˜ìœ„ ë©”ë‰´ í¼ì¹˜ê¸°)
        XPATH_HANDOVER_PARENT_MENU = "//span[text()='ì¸ìˆ˜ì¸ê³„']"
        
        logger.info("ğŸ” 'ì¸ìˆ˜ì¸ê³„' ìƒìœ„ ë©”ë‰´ íƒìƒ‰ ì¤‘...")
        handover_parent = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, XPATH_HANDOVER_PARENT_MENU))
        )
        logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„' ìƒìœ„ ë©”ë‰´ ìš”ì†Œ ë°œê²¬")
        
        # ìš”ì†Œê°€ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤
        logger.info("ğŸ“œ ìš”ì†Œê°€ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤ ì¤‘...")
        driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", handover_parent)
        time.sleep(1)
        
        # í´ë¦­ ê°€ëŠ¥í•  ë•Œê¹Œì§€ ëŒ€ê¸°
        logger.info("â³ ìš”ì†Œê°€ í´ë¦­ ê°€ëŠ¥í•  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘...")
        WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, XPATH_HANDOVER_PARENT_MENU))
        )
        
        # í´ë¦­ ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•)
        click_success = False
        
        # ë°©ë²• 1: ì¼ë°˜ í´ë¦­
        try:
            logger.info("ğŸ–±ï¸ ë°©ë²• 1: ì¼ë°˜ í´ë¦­ ì‹œë„...")
            handover_parent.click()
            logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„' ìƒìœ„ ë©”ë‰´ í´ë¦­ ì„±ê³µ (ì¼ë°˜ í´ë¦­)")
            click_success = True
        except Exception as e:
            logger.warning(f"âš ï¸ ì¼ë°˜ í´ë¦­ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 2: JavaScript í´ë¦­
        if not click_success:
            try:
                logger.info("ğŸ–±ï¸ ë°©ë²• 2: JavaScript í´ë¦­ ì‹œë„...")
                driver.execute_script("arguments[0].click();", handover_parent)
                logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„' ìƒìœ„ ë©”ë‰´ í´ë¦­ ì„±ê³µ (JavaScript í´ë¦­)")
                click_success = True
            except Exception as e:
                logger.warning(f"âš ï¸ JavaScript í´ë¦­ ì‹¤íŒ¨: {e}")
        
        if not click_success:
            logger.error("âŒ ëª¨ë“  í´ë¦­ ë°©ë²• ì‹¤íŒ¨")
            return False
        
        # í•˜ìœ„ ë©”ë‰´ê°€ í¼ì³ì§ˆ ë•Œê¹Œì§€ ëŒ€ê¸°
        logger.info("â³ í•˜ìœ„ ë©”ë‰´ í¼ì³ì§ ëŒ€ê¸° ì¤‘...")
        time.sleep(2)
        
        # 3. 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ í´ë¦­
        XPATH_HANDOVER_DOCUMENT = "//span[text()='ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ']"
        
        logger.info("ğŸ” 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ íƒìƒ‰ ì¤‘...")
        handover_doc = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, XPATH_HANDOVER_DOCUMENT))
        )
        logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ ìš”ì†Œ ë°œê²¬")
        
        # ìš”ì†Œê°€ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤
        logger.info("ğŸ“œ ìš”ì†Œê°€ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤ ì¤‘...")
        driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", handover_doc)
        time.sleep(1)
        
        # í´ë¦­ ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•)
        click_success = False
        
        # ë°©ë²• 1: ì¼ë°˜ í´ë¦­
        try:
            logger.info("ğŸ–±ï¸ ë°©ë²• 1: ì¼ë°˜ í´ë¦­ ì‹œë„...")
            handover_doc.click()
            logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ í´ë¦­ ì„±ê³µ (ì¼ë°˜ í´ë¦­)")
            click_success = True
        except Exception as e:
            logger.warning(f"âš ï¸ ì¼ë°˜ í´ë¦­ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 2: JavaScript í´ë¦­
        if not click_success:
            try:
                logger.info("ğŸ–±ï¸ ë°©ë²• 2: JavaScript í´ë¦­ ì‹œë„...")
                driver.execute_script("arguments[0].click();", handover_doc)
                logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ í´ë¦­ ì„±ê³µ (JavaScript í´ë¦­)")
                click_success = True
            except Exception as e:
                logger.warning(f"âš ï¸ JavaScript í´ë¦­ ì‹¤íŒ¨: {e}")
        
        if not click_success:
            logger.error("âŒ ëª¨ë“  í´ë¦­ ë°©ë²• ì‹¤íŒ¨")
            return False
        
        # ìµœì¢… í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        logger.info("â³ ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ ëª©ë¡ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...")
        time.sleep(3)
        
        logger.info("âœ…âœ…âœ… 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ëª©ë¡ í˜ì´ì§€ ì´ë™ ì™„ë£Œ âœ…âœ…âœ…")
        return True
    
    except TimeoutException as te:
        logger.error(f"âŒ 2ë‹¨ê³„: íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ - {te}")
        # ë””ë²„ê¹…ì„ ìœ„í•œ ìŠ¤í¬ë¦°ìƒ· ì €ì¥
        try:
            driver.save_screenshot("debug_timeout_error.png")
            logger.info("ğŸ’¾ ë””ë²„ê¹…ìš© ìŠ¤í¬ë¦°ìƒ· ì €ì¥: debug_timeout_error.png")
        except:
            pass
        return False
    except Exception as e:
        logger.error(f"âŒ 2ë‹¨ê³„: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def get_last_12_months():
    """
    ìµœê·¼ 12ê°œì›”ì˜ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        Tuple[str, str]: (ì‹œì‘ì¼, ì¢…ë£Œì¼) YYYY-MM-DD í˜•ì‹
    """
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365)  # ì•½ 12ê°œì›” ì „
    
    return start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d")

def parse_date_range(start_date_str: str, end_date_str: str) -> Tuple[str, str]:
    """
    ì‚¬ìš©ì ì…ë ¥ ë‚ ì§œë¥¼ íŒŒì‹±í•˜ê³  ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        start_date_str (str): ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        end_date_str (str): ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
        
    Returns:
        Tuple[str, str]: (ì‹œì‘ì¼, ì¢…ë£Œì¼) YYYY-MM-DD í˜•ì‹
        
    Raises:
        ValueError: ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ëœ ê²½ìš°
    """
    try:
        start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
        end_date = datetime.strptime(end_date_str, "%Y-%m-%d")
        
        if start_date > end_date:
            raise ValueError("ì‹œì‘ ë‚ ì§œê°€ ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤")
        
        if end_date > datetime.now():
            raise ValueError("ì¢…ë£Œ ë‚ ì§œê°€ í˜„ì¬ ë‚ ì§œë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤")
            
        return start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d")
        
    except ValueError as e:
        if "time data" in str(e):
            raise ValueError("ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”")
        raise

def extract_document_list(driver, start_date: str, end_date: str, doc_keyword: str) -> List[Dict[str, Any]]:
    """
    ëª©ë¡ í˜ì´ì§€ì—ì„œ íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œë“¤ì˜ ë§í¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        driver: Selenium WebDriver ì¸ìŠ¤í„´ìŠ¤
        start_date (str): ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        end_date (str): ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
        doc_keyword (str): ë¬¸ì„œ ì œëª©ì— í¬í•¨ë  í‚¤ì›Œë“œ ('ë§¤ì¶œí’ˆì˜' ë˜ëŠ” 'ë§¤ì…í’ˆì˜')
        
    Returns:
        List[Dict[str, Any]]: ì¶”ì¶œëœ ë¬¸ì„œ ë§í¬ ë¦¬ìŠ¤íŠ¸ (ë¬¸ì„œì œëª©, ë§í¬, ë‚ ì§œ í¬í•¨)
    """
    documents = []
    
    try:
        logger.info(f"ğŸ“„ '{doc_keyword}' í‚¤ì›Œë“œ ë¬¸ì„œ ëª©ë¡ ì¶”ì¶œ ì¤‘...")
        
        # 1. HTML ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸° ë° BeautifulSoup íŒŒì‹±
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # [í•µì‹¬ ìˆ˜ì • 1: UL ì»¨í…Œì´ë„ˆ íƒìƒ‰ìœ¼ë¡œ ëŒ€ì²´] 
        document_list_container = soup.select_one('ul.tableBody') 
        
        if not document_list_container:
            logger.warning("âš ï¸ í’ˆì˜ì„œ ëª©ë¡ ì»¨í…Œì´ë„ˆ (ul.tableBody)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return documents

        # 2. LI í–‰ë“¤ ì¶”ì¶œ ë° cells ë¡œì§ ì œê±°
        rows = document_list_container.find_all('li', recursive=False)  
        logger.info(f"ğŸ“Š ì´ {len(rows)}ê°œì˜ í–‰ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        for idx, row in enumerate(rows, 1):
            try:
                # 1. ë¬¸ì„œ ì œëª© ì¶”ì¶œ (titDiv .title span)
                title_element = row.select_one('.titDiv .title span')
                if not title_element:
                    # ì œëª© í…ìŠ¤íŠ¸ë¥¼ ê°€ì§„ spanì´ ì—†ì„ ê²½ìš°, title í´ë˜ìŠ¤ ìì²´ì˜ í…ìŠ¤íŠ¸ë¥¼ ì‹œë„ (ì•ˆì •ì„± ë³´ê°•)
                    title_element = row.select_one('.titDiv .title')
                    if not title_element: continue
                title = title_element.get_text(strip=True)
                
                # 2. ë¬¸ì„œë²ˆí˜¸/ë§í¬ ì¶”ì¶œ (infoDiv ë‚´ë¶€, ë‘ ë²ˆì§¸ infoLink í…ìŠ¤íŠ¸ ì‚¬ìš©)
                info_links_container = row.select_one('.infoDiv .h-box')
                if not info_links_container: continue

                info_links = info_links_container.find_all('div', class_=lambda x: x and 'txt' in x and 'infoLink' in x)
                if len(info_links) < 2: continue # í’ˆì˜ ì¢…ë¥˜ì™€ ë¬¸ì„œë²ˆí˜¸ 2ê°œê°€ ìˆì–´ì•¼ í•¨

                link_text_element = info_links[1] # ë‘ ë²ˆì§¸ infoLink (ë¬¸ì„œë²ˆí˜¸ í…ìŠ¤íŠ¸)
                link_href = link_text_element.get_text(strip=True) #ë¶€ì„œ ë° ë¬¸ì„œë²ˆí˜¸í˜¸
                
                # 3. ê¸°ì•ˆì¼ ì¶”ì¶œ (dateText í´ë˜ìŠ¤)
                date_text_element = row.select_one('.dateText')
                date_text = date_text_element.get_text(strip=True) if date_text_element else ""
                
                # 4. ìƒíƒœ í™•ì¸ (ì¢…ê²°/ì™„ë£Œëœ ë¬¸ì„œë§Œ)
                status_element = row.select_one('.process .ellipsis2')
                status = status_element.get_text(strip=True) if status_element else ""
                
                if 'ì¢…ê²°' not in status and 'ì™„ë£Œ' not in status: continue
                
                # 5. ë‚ ì§œ íŒŒì‹± ë° í•„í„°ë§ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                doc_date = parse_date_from_text(date_text)
                if not is_date_in_range(doc_date, start_date, end_date): continue
                print(doc_date)
                
                # 6. í‚¤ì›Œë“œ í•„í„°ë§ ë° ë°ì´í„° êµ¬ì¡°í™” (ê¸ˆì•¡ ë¡œì§ì€ ì™„ì „íˆ ì œê±°ë¨)
                if doc_keyword not in title: continue
                
                doc_type = 'ë§¤ì¶œí’ˆì˜' if 'ë§¤ì¶œí’ˆì˜' in title else 'ë§¤ì…í’ˆì˜'
                
                print(doc_date)
                print(title)
                print(link_href)
                print(doc_type)
                
                document_data = {
                    'ê¸°ì•ˆì¼': doc_date.strftime('%Y-%m-%d'),
                    'ë§¤ì¶œí’ˆì˜|ë§¤ì…í’ˆì˜': doc_type,
                    'ë¬¸ì„œì œëª©': title,
                    'ì‚¬ì—…ë³¸ë¶€-ë¬¸ì„œë²ˆí˜¸': link_href,
                    'ì¢…ê²°|ì™„ë£Œ' : status
                }
                
                documents.append(document_data)
                logger.debug(f"âœ… ë¬¸ì„œ ë§í¬ ì¶”ì¶œ: {title} - {doc_date.strftime('%Y-%m-%d')}")
                
            except Exception as e:
                logger.warning(f"âš ï¸ [{idx}/{len(rows)}] í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        logger.info(f"âœ… '{doc_keyword}' í‚¤ì›Œë“œ ë¬¸ì„œ {len(documents)}ê±´ ì¶”ì¶œ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ ë¬¸ì„œ ëª©ë¡ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
    
    return documents

def extract_detail_amount(driver) -> Dict[str, Any]:
    """
    íŒì—… ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¬ë¬´ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        driver: Selenium WebDriver ì¸ìŠ¤í„´ìŠ¤
        
    Returns:
        Dict[str, Any]: ì¶”ì¶œëœ ì¬ë¬´ ì •ë³´ (ê±°ë˜ì²˜ëª…, ê³µê¸‰ê°€ì•¡, ë¶€ê°€ì„¸, í•©ê³„ê¸ˆì•¡)
    """
    detail_data = {
        'ê±°ë˜ì²˜ëª…': '',
        'ê³µê¸‰ê°€ì•¡': 0,
        'ë¶€ê°€ì„¸': 0,
        'í•©ê³„ê¸ˆì•¡': 0
    }
    
    try:
        logger.info("ğŸ” ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì¤‘...")
        
        # í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë ˆì´ë¸” ê¸°ë°˜ìœ¼ë¡œ ê°’ ì¶”ì¶œ
        full_text = soup.get_text()
        
        # ê±°ë˜ì²˜ëª… ì¶”ì¶œ
        account_patterns = [
            r'ê±°ë˜ì²˜ëª…[:\s]*([^\n]+)',
            r'ê±°ë˜ì²˜[:\s]*([^\n]+)',
            r'ê±°ë˜ì²˜ëª…[:\s]*([ê°€-í£a-zA-Z0-9\s]+)'
        ]
        
        for pattern in account_patterns:
            match = re.search(pattern, full_text)
            if match:
                detail_data['ê±°ë˜ì²˜ëª…'] = match.group(1).strip()
                break
        
        # ê³µê¸‰ê°€ì•¡ ì¶”ì¶œ
        supply_patterns = [
            r'ê³µê¸‰ê°€ì•¡[:\s]*([\d,]+)',
            r'ê³µê¸‰ê°€[:\s]*([\d,]+)',
            r'ê³µê¸‰ê°€ì•¡[:\s]*([0-9,]+)'
        ]
        
        for pattern in supply_patterns:
            match = re.search(pattern, full_text)
            if match:
                try:
                    detail_data['ê³µê¸‰ê°€ì•¡'] = int(match.group(1).replace(',', ''))
                    break
                except ValueError:
                    continue
        
        # ë¶€ê°€ì„¸ ì¶”ì¶œ
        vat_patterns = [
            r'ë¶€ê°€ì„¸[:\s]*([\d,]+)',
            r'VAT[:\s]*([\d,]+)',
            r'ë¶€ê°€ì„¸[:\s]*([0-9,]+)'
        ]
        
        for pattern in vat_patterns:
            match = re.search(pattern, full_text)
            if match:
                try:
                    detail_data['ë¶€ê°€ì„¸'] = int(match.group(1).replace(',', ''))
                    break
                except ValueError:
                    continue
        
        # í•©ê³„ê¸ˆì•¡ ì¶”ì¶œ
        total_patterns = [
            r'í•©ê³„ê¸ˆì•¡[:\s]*([\d,]+)',
            r'í•©ê³„[:\s]*([\d,]+)',
            r'ì´ì•¡[:\s]*([\d,]+)',
            r'í•©ê³„ê¸ˆì•¡[:\s]*([0-9,]+)'
        ]
        
        for pattern in total_patterns:
            match = re.search(pattern, full_text)
            if match:
                try:
                    detail_data['í•©ê³„ê¸ˆì•¡'] = int(match.group(1).replace(',', ''))
                    break
                except ValueError:
                    continue
        
        logger.info(f"âœ… ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ: {detail_data}")
        
    except Exception as e:
        logger.error(f"âŒ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return detail_data

def close_popup(driver):
    """
    íŒì—…ì„ ë‹«ìŠµë‹ˆë‹¤.
    
    Args:
        driver: Selenium WebDriver ì¸ìŠ¤í„´ìŠ¤
        
    Returns:
        bool: íŒì—… ë‹«ê¸° ì„±ê³µ ì—¬ë¶€
    """
    try:
        logger.info("ğŸšª íŒì—… ë‹«ê¸° ì‹œë„ ì¤‘...")
        
        # ë‹¤ì–‘í•œ ë‹«ê¸° ë²„íŠ¼ ì„ íƒì
        close_selectors = [
            "//button[contains(text(), 'ë‹«ê¸°')]",
            "//button[contains(text(), 'X')]",
            "//span[contains(text(), 'ë‹«ê¸°')]",
            "//span[contains(text(), 'X')]",
            "//button[@class='close']",
            "//button[@class='btn-close']",
            "//*[@id='closeBtn']",
            "//*[@id='btnClose']"
        ]
        
        for selector in close_selectors:
            try:
                close_button = WebDriverWait(driver, 3).until(
                    EC.element_to_be_clickable((By.XPATH, selector))
                )
                close_button.click()
                logger.info(f"âœ… íŒì—… ë‹«ê¸° ì„±ê³µ: {selector}")
                time.sleep(1)
                return True
            except TimeoutException:
                continue
        
        # ë‹«ê¸° ë²„íŠ¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ESC í‚¤ ì‹œë„
        from selenium.webdriver.common.keys import Keys
        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.ESCAPE)
        logger.info("âœ… ESC í‚¤ë¡œ íŒì—… ë‹«ê¸° ì‹œë„")
        time.sleep(1)
        return True
        
    except Exception as e:
        logger.warning(f"âš ï¸ íŒì—… ë‹«ê¸° ì‹¤íŒ¨: {e}")
        return False

def run_full_crawling(driver, start_date: str, end_date: str) -> List[Dict[str, Any]]:
    """
    ì „ì²´ í¬ë¡¤ë§ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        driver: Selenium WebDriver ì¸ìŠ¤í„´ìŠ¤
        start_date (str): ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        end_date (str): ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
        
    Returns:
        List[Dict[str, Any]]: ì¶”ì¶œëœ ì „ì²´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    all_data = []
    
    try:
        logger.info("ğŸš€ ì „ì²´ í¬ë¡¤ë§ ì‹œì‘")
        
        # 'ë§¤ì¶œí’ˆì˜'ì™€ 'ë§¤ì…í’ˆì˜' í‚¤ì›Œë“œë¡œ ëª©ë¡ ì¶”ì¶œ
        keywords = ['ë§¤ì¶œí’ˆì˜', 'ë§¤ì…í’ˆì˜']
        
        for keyword in keywords:
            logger.info(f"ğŸ“‹ '{keyword}' ëª©ë¡ ì¶”ì¶œ ì¤‘...")
            
            # ëª©ë¡ í˜ì´ì§€ì—ì„œ ë¬¸ì„œ ë§í¬ ì¶”ì¶œ
            document_list = extract_document_list(driver, start_date, end_date, keyword)
            
            if not document_list:
                logger.warning(f"âš ï¸ '{keyword}' ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                continue
            
            logger.info(f"âœ… '{keyword}' ë¬¸ì„œ {len(document_list)}ê±´ ë°œê²¬")
            
            # ê° ë¬¸ì„œ ë§í¬ë¥¼ ìˆœíšŒí•˜ë©° ìƒì„¸ ì •ë³´ ì¶”ì¶œ
            for idx, doc in enumerate(document_list, 1):
                try:
                    logger.info(f"ğŸ“„ [{idx}/{len(document_list)}] {doc['ë¬¸ì„œì œëª©']} ì²˜ë¦¬ ì¤‘...")
                    
                    # a. ë¬¸ì„œ ë§í¬ í´ë¦­í•˜ì—¬ íŒì—… ë„ìš°ê¸°
                    try:
                        # ë§í¬ê°€ ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                        link = doc['ë§í¬']
                        if link.startswith('/'):
                            link = driver.current_url.rsplit('/', 1)[0] + link
                        elif not link.startswith('http'):
                            link = driver.current_url.rsplit('/', 1)[0] + '/' + link
                        
                        driver.get(link)
                        time.sleep(2)  # íŒì—… ë¡œë”© ëŒ€ê¸°
                        
                    except Exception as e:
                        logger.error(f"âŒ íŒì—… ì—´ê¸° ì‹¤íŒ¨: {e}")
                        continue
                    
                    # b. íŒì—… ë‚´ë¶€ ì •ë³´ ì¶”ì¶œ
                    detail_info = extract_detail_amount(driver)
                    
                    # ë¬¸ì„œ ì •ë³´ì™€ ìƒì„¸ ì •ë³´ í†µí•©
                    combined_data = {
                        **doc,
                        **detail_info
                    }
                    
                    all_data.append(combined_data)
                    logger.info(f"âœ… [{idx}/{len(document_list)}] ì¶”ì¶œ ì™„ë£Œ")
                    
                    # c. íŒì—… ë‹«ê¸°
                    close_popup(driver)
                    
                    # ëª©ë¡ í˜ì´ì§€ë¡œ ëŒì•„ê°€ê¸°
                    driver.back()
                    time.sleep(1)
                    
                except Exception as e:
                    logger.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
        
        # ìµœì¢… ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        import json
        import os
        
        output_dir = "output"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        output_file = os.path.join(output_dir, "temp_raw_data.json")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ: {len(all_data)}ê±´ì˜ ë°ì´í„°ë¥¼ {output_file}ì— ì €ì¥")
        
        return all_data
        
    except Exception as e:
        logger.error(f"âŒ ì „ì²´ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
        return all_data

def parse_date_from_text(date_text: str) -> datetime:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤. (YYYY-MM-DD ë˜ëŠ” MM-DD í˜•ì‹ ì§€ì›)
    
    Args:
        date_text (str): ë‚ ì§œê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ ('10-17 (ê¸ˆ)', '2025.10.17' ë“±)
        
    Returns:
        datetime: íŒŒì‹±ëœ ë‚ ì§œ
        
    Raises:
        ValueError: íŒŒì‹±ì— ì‹¤íŒ¨í–ˆì„ ê²½ìš°
    """
    
    # ë¶ˆí•„ìš”í•œ ê³µë°±, ê´„í˜¸, ìš”ì¼ ì •ë³´ ì œê±° (ì˜ˆ: '10-17 (ê¸ˆ)' -> '10-17')
    cleaned_text = re.sub(r'\s*\(.+\)', '', date_text).strip()
    
    # 1. ì›”-ì¼ í˜•ì‹ íŒŒì‹± ë¡œì§ ì¶”ê°€ (ëª©ë¡ í˜ì´ì§€ í˜•ì‹)
    month_day_pattern = r'(\d{1,2})[.-]\s*(\d{1,2})' 
    match_md = re.search(month_day_pattern, cleaned_text)
    
    if match_md:
        month, day = match_md.groups()
        current_year = datetime.now().year
        try:
            # ì—°ë„ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ í˜„ì¬ ì—°ë„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            return datetime(current_year, int(month), int(day))
        except ValueError:
            pass # ì˜ëª»ëœ ì›”/ì¼ì´ë©´ ë‹¤ìŒ íŒ¨í„´ ì‹œë„ (ë§¤ìš° ë“œë­„)

    
    # 2. ê¸°ì¡´ ì—°ë„ í¬í•¨ íŒ¨í„´ ì‹œë„
    date_patterns = [
        r'(\d{4})[.-](\d{1,2})[.-](\d{1,2})', # YYYY-MM-DD, YYYY.MM.DD
        r'(\d{4})/(\d{1,2})/(\d{1,2})',# YYYY/MM/DD
        r'(\d{1,2})[.-](\d{1,2})[.-](\d{4})',# MM-DD-YYYY, MM.DD.YYYY
    ]
    
    for pattern in date_patterns:
        match = re.search(pattern, cleaned_text)
        if match:
            groups = match.groups()
            if len(groups) == 3:
                try:
                    if len(groups[0]) == 4: # YYYY-MM-DD í˜•ì‹
                        year, month, day = groups
                    else: # MM-DD-YYYY í˜•ì‹
                        month, day, year = groups
                    
                    return datetime(int(year), int(month), int(day))
                except ValueError:
                    continue
    
    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ, ê¸°ë³¸ê°’ ë°˜í™˜ ëŒ€ì‹  ì˜¤ë¥˜ ë°œìƒ (ë””ë²„ê¹… ì§€ì›)
    raise ValueError(f"ë‚ ì§œ í…ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨: í˜•ì‹ '{date_text}'")

def is_date_in_range(date: datetime, start_date: str, end_date: str) -> bool:
    """
    ë‚ ì§œê°€ ì§€ì •ëœ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    
    Args:
        date (datetime): í™•ì¸í•  ë‚ ì§œ
        start_date (str): ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        end_date (str): ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
        
    Returns:
        bool: ë²”ìœ„ ë‚´ ì—¬ë¶€
    """
    try:
        start = datetime.strptime(start_date, "%Y-%m-%d")
        end = datetime.strptime(end_date, "%Y-%m-%d")
        return start <= date <= end
    except ValueError:
        return False

def crawl_all_data(driver, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ëª¨ë“  ë§¤ì¶œ/ë§¤ì… ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        driver: Selenium WebDriver ì¸ìŠ¤í„´ìŠ¤
        start_date (str): ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        end_date (str): ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
        
    Returns:
        pd.DataFrame: ì¶”ì¶œëœ ë°ì´í„° (ì»¬ëŸ¼: ['ë‚ ì§œ', 'ë¬¸ì„œì œëª©', 'êµ¬ë¶„', 'ê³µê¸‰ê°€ì•¡'])
    """
    try:
        logger.info("ğŸš€ ì „ì²´ ë°ì´í„° í¬ë¡¤ë§ ì‹œì‘")
        
        # í’ˆì˜ì„œ ëª©ë¡ í˜ì´ì§€ë¡œ ì´ë™ (ì´ë¯¸ navigate_to_handover_document_listë¡œ ì´ë™í–ˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ)
        # if not navigate_to_handover_document_list(driver):
        #     logger.error("âŒ í’ˆì˜ì„œ ëª©ë¡ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨")
        #     return pd.DataFrame(columns=['ë‚ ì§œ', 'ë¬¸ì„œì œëª©', 'êµ¬ë¶„', 'ê³µê¸‰ê°€ì•¡'])
        
        all_documents = []
        
        # ë§¤ì¶œ ë¬¸ì„œ ì¶”ì¶œ
        logger.info("ğŸ’° ë§¤ì¶œ ë¬¸ì„œ ì¶”ì¶œ ì¤‘...")
        sales_docs = extract_completed_documents(driver, start_date, end_date, 'ë§¤ì¶œ')
        all_documents.extend(sales_docs)
        
        # ë§¤ì… ë¬¸ì„œ ì¶”ì¶œ
        logger.info("ğŸ’¸ ë§¤ì… ë¬¸ì„œ ì¶”ì¶œ ì¤‘...")
        purchase_docs = extract_completed_documents(driver, start_date, end_date, 'ë§¤ì…')
        all_documents.extend(purchase_docs)
        
        # DataFrame ìƒì„±
        if all_documents:
            df = pd.DataFrame(all_documents)
            df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])
            df = df.sort_values('ë‚ ì§œ')
            logger.info(f"âœ… ì´ {len(df)}ê±´ì˜ ë°ì´í„° í¬ë¡¤ë§ ì™„ë£Œ")
        else:
            df = pd.DataFrame(columns=['ë‚ ì§œ', 'ë¬¸ì„œì œëª©', 'êµ¬ë¶„', 'ê³µê¸‰ê°€ì•¡'])
            logger.warning("âš ï¸ ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        return df
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame(columns=['ë‚ ì§œ', 'ë¬¸ì„œì œëª©', 'êµ¬ë¶„', 'ê³µê¸‰ê°€ì•¡'])

