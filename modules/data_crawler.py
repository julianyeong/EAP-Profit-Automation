"""
ë°ì´í„° í¬ë¡¤ë§ ëª¨ë“ˆ
Amaranth ê·¸ë£¹ì›¨ì–´ì—ì„œ ì¢…ê²°ëœ ë§¤ì¶œ/ë§¤ì… í’ˆì˜ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import time
import re
from datetime import datetime, timedelta
from typing import List, Tuple, Dict, Any
import pandas as pd
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from bs4 import BeautifulSoup
from selenium.webdriver import ActionChains
import logging

logger = logging.getLogger(__name__)

def _clean_amount(text: str) -> int:
    """
    ê¸ˆì•¡ ë¬¸ìì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    (ì‰¼í‘œ ì œê±° ë° ìˆ«ìë§Œ ì¶”ì¶œ)
    """
    if not text:
        return 0
    
    # ìˆ«ì(0-9)ì™€ ì‰¼í‘œ(,)ë¥¼ ì œì™¸í•œ ëª¨ë“  ë¬¸ìë¥¼ ì œê±°í•˜ê³  ì‰¼í‘œë¥¼ ì œê±°
    cleaned = re.sub(r'[^\d,]', '', text).replace(',', '')
    
    try:
        return int(cleaned)
    except ValueError:
        # ë³€í™˜ ì‹¤íŒ¨ ì‹œ 0 ë°˜í™˜ (ë°ì´í„° ì˜¤ë¥˜ ë°©ì§€)
        return 0

def _clean_text(text: str) -> str:
    """ í…ìŠ¤íŠ¸ì—ì„œ ê³µë°±, ì¤„ë°”ê¿ˆ, íŠ¹ìˆ˜ ê³µë°±ì„ ì œê±°í•˜ê³  ëª¨ë‘ ì†Œë¬¸ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤. """
    if not text:
        return ""
    # ëª¨ë“  ì¢…ë¥˜ì˜ ê³µë°± ë¬¸ì(ì¤„ë°”ê¿ˆ, íƒ­, ì¼ë°˜ ê³µë°±, nbsp ë“±) ì œê±°
    cleaned = re.sub(r'\s+', '', text.strip()).lower()
    return cleaned

def navigate_to_handover_document_list(driver):
    """
    1. 'ì „ìê²°ì¬' ë©”ë‰´ í´ë¦­
    2. 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ í´ë¦­ì„ í†µí•´ ìµœì¢… ëª©ì ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.
    """
    
    # 1. 'ì „ìê²°ì¬' ë©”ë‰´ í´ë¦­ (í˜ì´ì§€ ì´ë™)
    logger.info("1ë‹¨ê³„: ğŸ” 'ì „ìê²°ì¬' ë©”ë‰´ í´ë¦­ ì‹œë„ ì¤‘...")
    try:
        # ê°€ì¥ ì•ˆì •ì ì¸ í…ìŠ¤íŠ¸ ê¸°ë°˜ XPath ì‚¬ìš©
        XPATH_ELECTRONIC_APPROVAL = "//span[text()='ì „ìê²°ì¬']"
        
        WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, XPATH_ELECTRONIC_APPROVAL))
        ).click()
        
        logger.info("âœ… 'ì „ìê²°ì¬' ë©”ë‰´ í´ë¦­ ì„±ê³µ. í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...")
        
    except TimeoutException:
        logger.error("âŒ 1ë‹¨ê³„: 'ì „ìê²°ì¬' ë©”ë‰´ë¥¼ ì°¾ê±°ë‚˜ í´ë¦­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Timeout)")
        return False
    except Exception as e:
        logger.error(f"âŒ 1ë‹¨ê³„: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
    
    # --- í˜ì´ì§€ ì´ë™ í›„ ë¡œë”© ëŒ€ê¸° ë° 2ë‹¨ê³„ í´ë¦­ ì‹œì‘ ---

    logger.info("2ë‹¨ê³„: ğŸ” 'ì¸ìˆ˜ì¸ê³„' ë©”ë‰´ í™•ì¥ ë° 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' í´ë¦­ ì‹œë„ ì¤‘...")
    try:
        # 1. í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°: ìƒˆë¡œìš´ í˜ì´ì§€ì—ì„œ ê³ ìœ í•œ ìš”ì†Œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        XPATH_APPROVAL_CONTENT_AREA = "//div[@id='sideLnb']"
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.XPATH, XPATH_APPROVAL_CONTENT_AREA))
        )
        logger.info("âœ… ì „ìê²°ì¬ í˜ì´ì§€ ë‚´ë¶€ ìš”ì†Œ ë¡œë”© ì™„ë£Œ í™•ì¸.")
        
        # ì¶”ê°€ ì•ˆì •í™” ì‹œê°„
        time.sleep(2)
        
        # 2. 'ì¸ìˆ˜ì¸ê³„' ìƒìœ„ ë©”ë‰´ ì°¾ê¸° ë° í´ë¦­ (í•˜ìœ„ ë©”ë‰´ í¼ì¹˜ê¸°)
        XPATH_HANDOVER_PARENT_MENU = "//span[text()='ì¸ìˆ˜ì¸ê³„']"
        
        logger.info("ğŸ” 'ì¸ìˆ˜ì¸ê³„' ìƒìœ„ ë©”ë‰´ íƒìƒ‰ ì¤‘...")
        handover_parent = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, XPATH_HANDOVER_PARENT_MENU))
        )
        logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„' ìƒìœ„ ë©”ë‰´ ìš”ì†Œ ë°œê²¬")
        
        # ìš”ì†Œê°€ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤
        logger.info("ğŸ“œ ìš”ì†Œê°€ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤ ì¤‘...")
        driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", handover_parent)
        time.sleep(1)
        
        # í´ë¦­ ê°€ëŠ¥í•  ë•Œê¹Œì§€ ëŒ€ê¸°
        logger.info("â³ ìš”ì†Œê°€ í´ë¦­ ê°€ëŠ¥í•  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘...")
        WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, XPATH_HANDOVER_PARENT_MENU))
        )
        
        # í´ë¦­ ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•)
        click_success = False
        
        # ë°©ë²• 1: ì¼ë°˜ í´ë¦­
        try:
            logger.info("ğŸ–±ï¸ ë°©ë²• 1: ì¼ë°˜ í´ë¦­ ì‹œë„...")
            handover_parent.click()
            logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„' ìƒìœ„ ë©”ë‰´ í´ë¦­ ì„±ê³µ (ì¼ë°˜ í´ë¦­)")
            click_success = True
        except Exception as e:
            logger.warning(f"âš ï¸ ì¼ë°˜ í´ë¦­ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 2: JavaScript í´ë¦­
        if not click_success:
            try:
                logger.info("ğŸ–±ï¸ ë°©ë²• 2: JavaScript í´ë¦­ ì‹œë„...")
                driver.execute_script("arguments[0].click();", handover_parent)
                logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„' ìƒìœ„ ë©”ë‰´ í´ë¦­ ì„±ê³µ (JavaScript í´ë¦­)")
                click_success = True
            except Exception as e:
                logger.warning(f"âš ï¸ JavaScript í´ë¦­ ì‹¤íŒ¨: {e}")
        
        if not click_success:
            logger.error("âŒ ëª¨ë“  í´ë¦­ ë°©ë²• ì‹¤íŒ¨")
            return False
        
        # í•˜ìœ„ ë©”ë‰´ê°€ í¼ì³ì§ˆ ë•Œê¹Œì§€ ëŒ€ê¸°
        logger.info("â³ í•˜ìœ„ ë©”ë‰´ í¼ì³ì§ ëŒ€ê¸° ì¤‘...")
        time.sleep(2)
        
        # 3. 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ í´ë¦­
        XPATH_HANDOVER_DOCUMENT = "//span[text()='ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ']"
        
        logger.info("ğŸ” 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ íƒìƒ‰ ì¤‘...")
        handover_doc = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, XPATH_HANDOVER_DOCUMENT))
        )
        logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ ìš”ì†Œ ë°œê²¬")
        
        # ìš”ì†Œê°€ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤
        logger.info("ğŸ“œ ìš”ì†Œê°€ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤ ì¤‘...")
        driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", handover_doc)
        time.sleep(1)
        
        # í´ë¦­ ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•)
        click_success = False
        
        # ë°©ë²• 1: ì¼ë°˜ í´ë¦­
        try:
            logger.info("ğŸ–±ï¸ ë°©ë²• 1: ì¼ë°˜ í´ë¦­ ì‹œë„...")
            handover_doc.click()
            logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ í´ë¦­ ì„±ê³µ (ì¼ë°˜ í´ë¦­)")
            click_success = True
        except Exception as e:
            logger.warning(f"âš ï¸ ì¼ë°˜ í´ë¦­ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 2: JavaScript í´ë¦­
        if not click_success:
            try:
                logger.info("ğŸ–±ï¸ ë°©ë²• 2: JavaScript í´ë¦­ ì‹œë„...")
                driver.execute_script("arguments[0].click();", handover_doc)
                logger.info("âœ… 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ì„œë¸Œ ë©”ë‰´ í´ë¦­ ì„±ê³µ (JavaScript í´ë¦­)")
                click_success = True
            except Exception as e:
                logger.warning(f"âš ï¸ JavaScript í´ë¦­ ì‹¤íŒ¨: {e}")
        
        if not click_success:
            logger.error("âŒ ëª¨ë“  í´ë¦­ ë°©ë²• ì‹¤íŒ¨")
            return False
        
        # ìµœì¢… í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        logger.info("â³ ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ ëª©ë¡ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...")
        time.sleep(3)
        
        logger.info("âœ…âœ…âœ… 'ì¸ìˆ˜ì¸ê³„ë¬¸ì„œ' ëª©ë¡ í˜ì´ì§€ ì´ë™ ì™„ë£Œ âœ…âœ…âœ…")
        return True
    
    except TimeoutException as te:
        logger.error(f"âŒ 2ë‹¨ê³„: íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ - {te}")
        # ë””ë²„ê¹…ì„ ìœ„í•œ ìŠ¤í¬ë¦°ìƒ· ì €ì¥
        try:
            driver.save_screenshot("debug_timeout_error.png")
            logger.info("ğŸ’¾ ë””ë²„ê¹…ìš© ìŠ¤í¬ë¦°ìƒ· ì €ì¥: debug_timeout_error.png")
        except:
            pass
        return False
    except Exception as e:
        logger.error(f"âŒ 2ë‹¨ê³„: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def get_last_12_months():
    """
    ìµœê·¼ 12ê°œì›”ì˜ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        Tuple[str, str]: (ì‹œì‘ì¼, ì¢…ë£Œì¼) YYYY-MM-DD í˜•ì‹
    """
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365)  # ì•½ 12ê°œì›” ì „
    
    return start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d")

def parse_date_range(start_date_str: str, end_date_str: str) -> Tuple[str, str]:
    """
    ì‚¬ìš©ì ì…ë ¥ ë‚ ì§œë¥¼ íŒŒì‹±í•˜ê³  ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        start_date_str (str): ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        end_date_str (str): ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
        
    Returns:
        Tuple[str, str]: (ì‹œì‘ì¼, ì¢…ë£Œì¼) YYYY-MM-DD í˜•ì‹
        
    Raises:
        ValueError: ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ëœ ê²½ìš°
    """
    try:
        start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
        end_date = datetime.strptime(end_date_str, "%Y-%m-%d")
        
        if start_date > end_date:
            raise ValueError("ì‹œì‘ ë‚ ì§œê°€ ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤")
        
        if end_date > datetime.now():
            raise ValueError("ì¢…ë£Œ ë‚ ì§œê°€ í˜„ì¬ ë‚ ì§œë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤")
            
        return start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d")
        
    except ValueError as e:
        if "time data" in str(e):
            raise ValueError("ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”")
        raise

def extract_document_list(driver, start_date: str, end_date: str, doc_keyword: str) -> List[Dict[str, Any]]:
    """
    ëª©ë¡ í˜ì´ì§€ì—ì„œ íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œë“¤ì˜ ë§í¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    (íŠ¹ì • ëª©ë¡ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ìŠ¤í¬ë¡¤ ë¡œì§ ì ìš©)
    """
    documents = []
    
    try:
        logger.info(f"ğŸ“„ '{doc_keyword}' í‚¤ì›Œë“œ ë¬¸ì„œ ëª©ë¡ ì¶”ì¶œ ì¤‘...")
        
        # 1. ìŠ¤í¬ë¡¤ ëŒ€ìƒ ìš”ì†Œ ì°¾ê¸° (ì¸ë¼ì¸ ìŠ¤íƒ€ì¼ ì†ì„±ì„ ì´ìš©í•œ ì •í™•í•œ íƒìƒ‰)
        # CSS Selector: style ì†ì„±ì— 'overflow: scroll'ì„ í¬í•¨í•˜ëŠ” ëª¨ë“  DIV
        SCROLL_CONTAINER_CSS = "div[style*='overflow: scroll']"
        
        try:
            # 10ì´ˆ ëŒ€ê¸°í•˜ì—¬ ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ìš”ì†Œ í™•ë³´
            scrollable_element = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, SCROLL_CONTAINER_CSS))
            )
            logger.info("âœ… ìŠ¤í¬ë¡¤ ëŒ€ìƒ ìš”ì†Œ (style*='overflow: scroll') ì°¾ê¸° ì„±ê³µ")
        except TimeoutException:
            logger.error("âŒ ìŠ¤í¬ë¡¤ ëŒ€ìƒ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ëª©ë¡ ì˜ì—­ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return documents
        
        # 2. ë°˜ë³µ ìŠ¤í¬ë¡¤ ë¡œì§ ì‹¤í–‰ (ì „ì²´ ëª©ë¡ ë¡œë“œë¥¼ ë³´ì¥)
        last_height = 0 
        max_attempts = 15 # ì¶©ë¶„í•œ ì‹œë„ íšŸìˆ˜

        for i in range(max_attempts):
            logger.info(f"ğŸ“œ [{i+1}ì°¨ ìŠ¤í¬ë¡¤] ëª©ë¡ ìµœí•˜ë‹¨ìœ¼ë¡œ ìŠ¤í¬ë¡¤ ì¤‘...")
            
            # ìŠ¤í¬ë¡¤ ëª…ë ¹ ì‹¤í–‰ (ìš”ì†Œ ë‚´ë¶€ ìŠ¤í¬ë¡¤ì„ ìµœí•˜ë‹¨ìœ¼ë¡œ)
            driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight", scrollable_element)
            time.sleep(3) # ë°ì´í„° ë¡œë”© ë° ì•ˆì •í™” ëŒ€ê¸°
            
            # ìƒˆ ë†’ì´ ê°€ì ¸ì˜¤ê¸°
            new_height = driver.execute_script("return arguments[0].scrollHeight", scrollable_element)
            
            # ìŠ¤í¬ë¡¤ ë†’ì´ê°€ ë³€í•˜ì§€ ì•Šìœ¼ë©´ ì¢…ë£Œ
            if new_height == last_height:
                logger.info("âœ… ë” ì´ìƒ ìƒˆë¡œìš´ í–‰ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ìŠ¤í¬ë¡¤ ì¢…ë£Œ.")
                break 
                
            last_height = new_height
            
        logger.info(f"âœ… ë°˜ë³µ ìŠ¤í¬ë¡¤ ì™„ë£Œ.")
        
        # 2. HTML ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸° ë° BeautifulSoup íŒŒì‹±
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # [UL ì»¨í…Œì´ë„ˆ íƒìƒ‰]
        document_list_container = soup.select_one('ul.tableBody') 
        
        if not document_list_container:
            logger.warning("âš ï¸ í’ˆì˜ì„œ ëª©ë¡ ì»¨í…Œì´ë„ˆ (ul.tableBody)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return documents

        # 2. LI í–‰ë“¤ ì¶”ì¶œ
        rows = document_list_container.find_all('li', recursive=False) 
        logger.info(f"ğŸ“Š ì´ {len(rows)}ê°œì˜ í–‰ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        for idx, row in enumerate(rows, 1):
            try:
                # 1. ë¬¸ì„œ ì œëª© ì¶”ì¶œ
                title_element = row.select_one('.titDiv .title span')
                if not title_element:
                    title_element = row.select_one('.titDiv .title')
                    if not title_element: continue
                title = title_element.get_text(strip=True)
                
                # 2. ë¬¸ì„œë²ˆí˜¸/ë§í¬ ì¶”ì¶œ
                info_links_container = row.select_one('.infoDiv .h-box')
                if not info_links_container: continue

                info_links = info_links_container.find_all('div', class_=lambda x: x and 'txt' in x and 'infoLink' in x)
                if len(info_links) < 2: continue

                link_text_element = info_links[1] 
                link_href = link_text_element.get_text(strip=True) # í’ˆì˜ë²ˆí˜¸ í…ìŠ¤íŠ¸

                # 3. ê¸°ì•ˆì¼, ìƒíƒœ í™•ì¸ ë° í•„í„°ë§ (ìƒëµëœ ë¡œì§)
                date_text = row.select_one('.dateText').get_text(strip=True)
                status = row.select_one('.process .ellipsis2').get_text(strip=True)
                
                if 'ì¢…ê²°' not in status and 'ì™„ë£Œ' not in status: continue
                
                # NOTE: parse_date_from_text, is_date_in_range í•¨ìˆ˜ëŠ” ì™¸ë¶€ì—ì„œ ì •ì˜ë˜ì—ˆë‹¤ê³  ê°€ì •
                doc_date = parse_date_from_text(date_text)
                if not is_date_in_range(doc_date, start_date, end_date): continue
                
                # 4. í‚¤ì›Œë“œ í•„í„°ë§ ë° ë°ì´í„° êµ¬ì¡°í™”
                if doc_keyword not in title: continue
                doc_type = 'ë§¤ì¶œí’ˆì˜' if 'ë§¤ì¶œí’ˆì˜' in title else 'ë§¤ì…í’ˆì˜'

                document_data = {
                    'ê¸°ì•ˆì¼': doc_date.strftime('%Y-%m-%d'),
                    'ë¬¸ì„œì œëª©': title,
                    'ë§í¬': link_href, 
                    'êµ¬ë¶„': doc_type
                }
                
                documents.append(document_data)
                logger.debug(f"âœ… ë¬¸ì„œ ë§í¬ ì¶”ì¶œ: {title} - {doc_date.strftime('%Y-%m-%d')}")
                
            except Exception as e:
                logger.warning(f"âš ï¸ [{idx}/{len(rows)}] í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        logger.info(f"âœ… '{doc_keyword}' í‚¤ì›Œë“œ ë¬¸ì„œ {len(documents)}ê±´ ì¶”ì¶œ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ ë¬¸ì„œ ëª©ë¡ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
    
    return documents

def _extract_purchase_details(soup: BeautifulSoup) -> Dict[str, Any]:
    """
    ë§¤ì…í’ˆì˜ ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¬ë¬´ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    (ë°°ê²½ìƒ‰ ìŠ¤íƒ€ì¼ ì†ì„±ì„ ê°€ì§„ <td> ì…€ì„ ì§ì ‘ íƒìƒ‰)
    """
    detail_data = {
        'ê±°ë˜ì²˜ëª…': '',
        'ê³µê¸‰ê°€ì•¡': 0,
        'ë¶€ê°€ì„¸': 0,
        'í•©ê³„ê¸ˆì•¡': 0
    }
    
    try:
        target_style = 'background:rgb(255, 241, 214)'
        sum_cells = soup.find_all(['td', 'th'], 
                                  style=lambda s: s and target_style in s)
        
        if len(sum_cells) < 3:
            logger.warning("âš ï¸ íŠ¹ì • ë°°ê²½ìƒ‰ ìŠ¤íƒ€ì¼ì„ ê°€ì§„ ì…€ì„ ì¶©ë¶„íˆ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ìµœì†Œ 3ê°œ í•„ìš”)")
            return detail_data

        # ğŸ’¡ ì¶”ì¶œ ëª©í‘œ: í•©ê³„ê¸ˆì•¡, ë¶€ê°€ì„¸, ê³µê¸‰ê°€ì•¡ (ë’¤ì—ì„œ -1, -2, -3 ì¸ë±ìŠ¤)
        detail_data['í•©ê³„ê¸ˆì•¡'] = _clean_amount(sum_cells[-1].get_text(strip=True))
        detail_data['ë¶€ê°€ì„¸'] = _clean_amount(sum_cells[-2].get_text(strip=True))
        detail_data['ê³µê¸‰ê°€ì•¡'] = _clean_amount(sum_cells[-3].get_text(strip=True))
        logger.info("âœ… ë§¤ì…í’ˆì˜ ìŠ¤íƒ€ì¼ ì†ì„± ê¸°ë°˜ ê¸ˆì•¡ ì¶”ì¶œ ì„±ê³µ")
        
    except Exception as e:
        logger.error(f"âŒ ë§¤ì…í’ˆì˜ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
    return detail_data

def _extract_sales_details_kakao(soup: BeautifulSoup) -> Dict[str, Any]:
    """
    ë§¤ì¶œí’ˆì˜ ì¹´ì¹´ì˜¤í´ë¼ìš°ë“œ ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¬ë¬´ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ('í•© ê³„' ë ˆì´ë¸”ì„ ì°¾ì•„ 9ë²ˆì§¸ ì…€ì—ì„œ í•©ê³„ê¸ˆì•¡ë§Œ ì¶”ì¶œ)
    """
    detail_data = {
        'ê±°ë˜ì²˜ëª…': '',
        'ê³µê¸‰ê°€ì•¡': 0,
        'ë¶€ê°€ì„¸': 0,
        'í•©ê³„ê¸ˆì•¡': 0
    }
    
    try:
        # 'í•© ê³„' í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” <tr> ì°¾ê¸° (ê³µë°± ì •ë¦¬í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ë§¤ì¹­)
        total_rows = soup.find_all('tr')
        total_row = None
        
        for row in total_rows:
            row_text = re.sub(r'\s+', '', row.get_text(strip=True))
            if 'í•©ê³„' in row_text and 'í•©ê³„' in re.sub(r'\s+', '', row.get_text(strip=True)):
                total_row = row
                break
        
        if not total_row:
            logger.warning("âš ï¸ 'í•© ê³„' í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return detail_data
        
        # í•´ë‹¹ í–‰ì˜ ëª¨ë“  ì…€ ì¶”ì¶œ
        cells = total_row.find_all(['td', 'th'])
        
        if len(cells) >= 9:
            # 9ë²ˆì§¸ ì…€ (ì¸ë±ìŠ¤ 8)ì—ì„œ í•©ê³„ê¸ˆì•¡ ì¶”ì¶œ
            detail_data['í•©ê³„ê¸ˆì•¡'] = _clean_amount(cells[8].get_text(strip=True))
            logger.info("âœ… ì¹´ì¹´ì˜¤í´ë¼ìš°ë“œ í•©ê³„ê¸ˆì•¡ ì¶”ì¶œ ì„±ê³µ")
        else:
            logger.warning(f"âš ï¸ ì…€ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. {len(cells)}ê°œë§Œ ë°œê²¬ (9ê°œ í•„ìš”)")
        
    except Exception as e:
        logger.error(f"âŒ ì¹´ì¹´ì˜¤í´ë¼ìš°ë“œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
    return detail_data

def _extract_sales_details_general(soup: BeautifulSoup) -> Dict[str, Any]:
    """
    ë§¤ì¶œí’ˆì˜ ì¼ë°˜ êµ¬ì¡° ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¬ë¬´ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    (ì •ì œëœ í…ìŠ¤íŠ¸ ë ˆì´ë¸” ê¸°ë°˜ìœ¼ë¡œ ì¸ì ‘í•œ ê°’ ì…€ì„ ì°¾ì•„ ì¶”ì¶œí•˜ëŠ” ìµœì í™”ëœ ë¡œì§)
    """
    detail_data = {
        'ê±°ë˜ì²˜ëª…': '',
        'ê³µê¸‰ê°€ì•¡': 0,
        'ë¶€ê°€ì„¸': 0,
        'í•©ê³„ê¸ˆì•¡': 0
    }
    
    try:
        # 1. 'ë°œí–‰ê¸ˆì•¡' í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” <tr> í–‰ì„ ì°¾ìŠµë‹ˆë‹¤. (í–‰ì„ ì°¾ëŠ” ìµœì´ˆ í•„í„°ë§)
        # ì´ í–‰ì—ëŠ” 'ë°œí–‰ê¸ˆì•¡' ë ˆì´ë¸”ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì´ í–‰ì„ ë¨¼ì € í•„í„°ë§í•©ë‹ˆë‹¤.
        target_row = None
        for row in soup.find_all('tr'):
             if 'ë°œí–‰ê¸ˆì•¡' in row.get_text():
                 target_row = row
                 break
        
        if not target_row:
            logger.warning("âš ï¸ 'ë°œí–‰ê¸ˆì•¡' í–‰(ë ˆì´ë¸”)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return detail_data

        logger.info("âœ… 'ë°œí–‰ê¸ˆì•¡' í–‰ íƒìƒ‰ ì„±ê³µ. ë ˆì´ë¸” ê¸°ë°˜ ê°’ ì¶”ì¶œ ì‹œì‘.")
        
        # 2. í–‰ ë‚´ì—ì„œ ë ˆì´ë¸”ì„ ì°¾ê³  ë°”ë¡œ ì˜† ì…€(Next Sibling)ì—ì„œ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        labels_to_find = {
            'ê³µê¸‰ê°€ì•¡': 'ê³µê¸‰ê°€ì•¡',
            'ë¶€ê°€ì„¸': 'ë¶€ê°€ì„¸',
            'í•©ê³„ê¸ˆì•¡': 'í•©ê³„ê¸ˆì•¡'
        }
        
        # í–‰ ë‚´ì˜ ëª¨ë“  ì…€ì„ ë°˜ë³µí•˜ë©° ë ˆì´ë¸”ì„ ì°¾ìŠµë‹ˆë‹¤.
        for cell in target_row.find_all(['td', 'th']):
            cell_clean_text = _clean_text(cell.get_text())
            
            # ë ˆì´ë¸”ì„ ì°¾ì•˜ë‹¤ë©´, ë°”ë¡œ ë‹¤ìŒ í˜•ì œ ì…€ì—ì„œ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
            if 'ê³µê¸‰ê°€ì•¡' in cell_clean_text and detail_data['ê³µê¸‰ê°€ì•¡'] == 0:
                value_cell = cell.find_next_sibling(['td', 'th'])
                if value_cell:
                    detail_data['ê³µê¸‰ê°€ì•¡'] = _clean_amount(value_cell.get_text(strip=True))
                    logger.debug(f"âœ… ê³µê¸‰ê°€ì•¡ ì¶”ì¶œ ì™„ë£Œ: {detail_data['ê³µê¸‰ê°€ì•¡']}")

            elif 'ë¶€ê°€ì„¸' in cell_clean_text and detail_data['ë¶€ê°€ì„¸'] == 0:
                value_cell = cell.find_next_sibling(['td', 'th'])
                if value_cell:
                    detail_data['ë¶€ê°€ì„¸'] = _clean_amount(value_cell.get_text(strip=True))
                    logger.debug(f"âœ… ë¶€ê°€ì„¸ ì¶”ì¶œ ì™„ë£Œ: {detail_data['ë¶€ê°€ì„¸']}")
            
            elif 'í•©ê³„ê¸ˆì•¡' in cell_clean_text and detail_data['í•©ê³„ê¸ˆì•¡'] == 0:
                value_cell = cell.find_next_sibling(['td', 'th'])
                if value_cell:
                    detail_data['í•©ê³„ê¸ˆì•¡'] = _clean_amount(value_cell.get_text(strip=True))
                    logger.debug(f"âœ… í•©ê³„ê¸ˆì•¡ ì¶”ì¶œ ì™„ë£Œ: {detail_data['í•©ê³„ê¸ˆì•¡']}")
                    
            # ëª¨ë“  ê°’ì„ ì°¾ì•˜ìœ¼ë©´ ì¢…ë£Œ (ì˜µì…˜)
            if detail_data['ê³µê¸‰ê°€ì•¡'] != 0 and detail_data['ë¶€ê°€ì„¸'] != 0 and detail_data['í•©ê³„ê¸ˆì•¡'] != 0:
                break
        
    except Exception as e:
        logger.error(f"âŒ ë§¤ì¶œí’ˆì˜(ì¼ë°˜) ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
    return detail_data

def extract_detail_amount(driver, document_type: str, document_title: str = '') -> Dict[str, Any]:
    """
    íŒì—… ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¬ë¬´ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        driver: Selenium WebDriver ì¸ìŠ¤í„´ìŠ¤
        document_type: ë¬¸ì„œ ì¢…ë¥˜ ('ë§¤ì¶œí’ˆì˜' ë˜ëŠ” 'ë§¤ì…í’ˆì˜')
        document_title: ë¬¸ì„œ ì œëª© (ì¹´ì¹´ì˜¤í´ë¼ìš°ë“œ ë¶„ê¸°ë¥¼ ìœ„í•´ í•„ìš”)
        
    Returns:
        Dict[str, Any]: ì¶”ì¶œëœ ì¬ë¬´ ì •ë³´ (ê±°ë˜ì²˜ëª…, ê³µê¸‰ê°€ì•¡, ë¶€ê°€ì„¸, í•©ê³„ê¸ˆì•¡)
    """
    detail_data = {
        'ê±°ë˜ì²˜ëª…': '',
        'ê³µê¸‰ê°€ì•¡': 0,
        'ë¶€ê°€ì„¸': 0,
        'í•©ê³„ê¸ˆì•¡': 0
    }
    
    try:
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # ë¶„ê¸° 1: 'ë§¤ì…í’ˆì˜'
        if document_type == 'ë§¤ì…í’ˆì˜':
            logger.info("ğŸ” ë§¤ì…í’ˆì˜ ì¶”ì¶œ ë¡œì§ ì‹¤í–‰")
            detail_data = _extract_purchase_details(soup)
        
        # ë¶„ê¸° 2: 'ë§¤ì¶œí’ˆì˜'
        elif document_type == 'ë§¤ì¶œí’ˆì˜':
            logger.info("ğŸ” ë§¤ì¶œí’ˆì˜ ì¶”ì¶œ ë¡œì§ ì‹¤í–‰")
            
            # Case 2-1: ì¹´ì¹´ì˜¤í´ë¼ìš°ë“œ
            if 'ì¹´ì¹´ì˜¤í´ë¼ìš°ë“œ' in document_title:
                logger.info("ğŸ” ì¹´ì¹´ì˜¤í´ë¼ìš°ë“œ ë¬¸ì„œ ê°ì§€")
                detail_data = _extract_sales_details_kakao(soup)
            # Case 2-2: ê·¸ ì™¸ (ì¼ë°˜ êµ¬ì¡°)
            else:
                logger.info("ğŸ” ì¼ë°˜ ë§¤ì¶œí’ˆì˜ ë¬¸ì„œ ê°ì§€")
                detail_data = _extract_sales_details_general(soup)
        
        # ë¶„ê¸°ë˜ì§€ ì•Šì€ ê²½ìš°
        else:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì„œ ì¢…ë¥˜: {document_type}")
            
        logger.info(f"âœ… ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ: {detail_data}")
        
    except Exception as e:
        logger.error(f"âŒ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
    return detail_data

def close_popup(driver):
    """
    íŒì—…ì„ ë‹«ìŠµë‹ˆë‹¤.
    (íŒì—…ì€ driver.close()ë¡œ ì²˜ë¦¬ë˜ë¯€ë¡œ ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤)
    """
    logger.info("ğŸšª íŒì—… ë‹«ê¸°ëŠ” ìœˆë„ìš° ì»¨í…ìŠ¤íŠ¸ ì „í™˜ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤")
    return True

def run_full_crawling(driver, start_date: str, end_date: str) -> List[Dict[str, Any]]:
    """
    ì „ì²´ í¬ë¡¤ë§ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    (íŒì—…(ìƒˆ ì°½)ì´ ì—´ë¦¬ëŠ” í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ ìœˆë„ìš° í•¸ë“¤ ì „í™˜ ë¡œì§ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.)
    """
    all_data = []
    
    try:
        logger.info("ğŸš€ ì „ì²´ í¬ë¡¤ë§ ì‹œì‘")
        
        keywords = ['ë§¤ì¶œí’ˆì˜', 'ë§¤ì…í’ˆì˜']
        
        for keyword in keywords:
            logger.info(f"ğŸ“‹ '{keyword}' ëª©ë¡ ì¶”ì¶œ ì¤‘...")
            
            # 1. ëª©ë¡ í˜ì´ì§€ì—ì„œ ë¬¸ì„œ ë§í¬ ì¶”ì¶œ
            document_list = extract_document_list(driver, start_date, end_date, keyword)
            
            if not document_list:
                logger.warning(f"âš ï¸ '{keyword}' ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                continue
            
            logger.info(f"âœ… '{keyword}' ë¬¸ì„œ {len(document_list)}ê±´ ë°œê²¬")
            
            # 2. ê° ë¬¸ì„œ ë§í¬ë¥¼ ìˆœíšŒí•˜ë©° ìƒì„¸ ì •ë³´ ì¶”ì¶œ (íŒì—… ì œì–´)
            for idx, doc in enumerate(document_list, 1):
                list_window = driver.current_window_handle # í˜„ì¬(ëª©ë¡) ì°½ í•¸ë“¤ ì €ì¥
                
                try:
                    logger.info(f"ğŸ“„ [{idx}/{len(document_list)}] {doc['ë¬¸ì„œì œëª©']} ì²˜ë¦¬ ì¤‘...")
                    
                    # --- a. ë¬¸ì„œ ì œëª© ìš”ì†Œ ì°¾ê¸° ë° í´ë¦­í•˜ì—¬ íŒì—… ë„ìš°ê¸° ---
                    XPATH_DOC_TITLE = f"//span[text()=\"{doc['ë¬¸ì„œì œëª©']}\"]" 
                    
                    title_span = WebDriverWait(driver, 10).until(
                        EC.element_to_be_clickable((By.XPATH, XPATH_DOC_TITLE))
                    )
                    
                    # JavaScript ê°•ì œ í´ë¦­ (íŒì—…ì„ ë„ìš°ëŠ” ì˜¬ë°”ë¥¸ ë™ì‘)
                    driver.execute_script("arguments[0].click();", title_span)
                    logger.info("âœ… ë¬¸ì„œ ì œëª© í´ë¦­ ì„±ê³µ. íŒì—… ë¡œë”© ëŒ€ê¸° ì¤‘...")
                    time.sleep(2) # íŒì—… ì°½ì´ ì™„ì „íˆ ëœ¨ê¸°ë¥¼ ìœ„í•œ ì§§ì€ ê³ ì • ëŒ€ê¸°

                    # *** ğŸŒŸ íŒì—…(ìƒˆ ì°½) ì»¨í…ìŠ¤íŠ¸ ì „í™˜ ğŸŒŸ ***
                    new_window = None
                    all_windows = driver.window_handles
                    
                    # ëª©ë¡ ì°½ì„ ì œì™¸í•œ ìƒˆë¡œìš´ íŒì—… ì°½ í•¸ë“¤ ì°¾ê¸°
                    for window in all_windows:
                        if window != list_window:
                            new_window = window
                            driver.switch_to.window(new_window)
                            logger.info(f"âœ… ìœˆë„ìš° ì „í™˜ ì„±ê³µ: ìƒˆ íŒì—… ì°½ìœ¼ë¡œ ì´ë™")
                            break
                    
                    if not new_window:
                        logger.warning("âš ï¸ íŒì—… ì°½ì´ ê°ì§€ë˜ì§€ ì•Šì•„ ìœˆë„ìš° ì „í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ëª©ë¡ í˜ì´ì§€ ìœ ì§€.")
                        continue # ë‹¤ìŒ ë¬¸ì„œë¡œ ì´ë™ (ëª©ë¡ ì°½ìœ¼ë¡œ ê³„ì† ì§„í–‰)
                    # *** ğŸŒŸ íŒì—… ì»¨í…ìŠ¤íŠ¸ ì „í™˜ ì¢…ë£Œ ğŸŒŸ ***
                    
                    # --- b. íŒì—… ë‚´ë¶€ ì •ë³´ ì¶”ì¶œ (driverëŠ” íŒì—…ì„ ë³´ê³  ìˆìŒ) ---
                    doc_type = doc.get('êµ¬ë¶„', '')
                    doc_title = doc.get('ë¬¸ì„œì œëª©', '')
                    detail_info = extract_detail_amount(driver, doc_type, doc_title) 
                    
                    # --- c. íŒì—… ë‹«ê¸° ë° í†µí•© ---
                    # íŒì—… ì°½ ë‹«ê¸°
                    driver.close() 

                    # ë©”ì¸(ëª©ë¡) ì°½ìœ¼ë¡œ ë‹¤ì‹œ ì „í™˜
                    driver.switch_to.window(list_window)
                    logger.info("âœ… íŒì—… ë‹«ê¸° ë° ë©”ì¸ ì°½ ë³µê·€ ì™„ë£Œ.")
                    
                    # ë¬¸ì„œ ì •ë³´ì™€ ìƒì„¸ ì •ë³´ í†µí•©
                    combined_data = {
                        **doc,
                        **detail_info
                    }
                    all_data.append(combined_data)
                    logger.info(f"âœ… [{idx}/{len(document_list)}] ë°ì´í„° í†µí•© ì™„ë£Œ")
                        
                except Exception as e:
                    logger.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë³µêµ¬ ë¡œì§: íŒì—…ì´ ì—´ë ¤ìˆë‹¤ë©´ ë‹«ê³  ë©”ì¸ ì°½ìœ¼ë¡œ ë³µê·€
                    try: 
                        # íŒì—…ì´ ì—´ë¦° ì±„ ì—ëŸ¬ê°€ ë°œìƒí–ˆë‹¤ë©´ ë‹«ê³  ë©”ì¸ìœ¼ë¡œ ë³µê·€
                        if driver.current_window_handle != list_window:
                            driver.close()
                            driver.switch_to.window(list_window)
                    except: 
                        logger.error("ğŸš¨ ì˜¤ë¥˜ ë³µêµ¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ. ë“œë¼ì´ë²„ ìƒíƒœ í™•ì¸ í•„ìš”.")
                    
                    continue # ë‹¤ìŒ ë¬¸ì„œë¡œ ì´ë™
                    
    except Exception as e:
        logger.error(f"âŒ ì „ì²´ í¬ë¡¤ë§ íŒŒì´í”„ë¼ì¸ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
    return all_data

def parse_date_from_text(date_text: str) -> datetime:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤. (YYYY-MM-DD ë˜ëŠ” MM-DD í˜•ì‹ ì§€ì›)
    
    Args:
        date_text (str): ë‚ ì§œê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ ('10-17 (ê¸ˆ)', '2025.10.17' ë“±)
        
    Returns:
        datetime: íŒŒì‹±ëœ ë‚ ì§œ
        
    Raises:
        ValueError: íŒŒì‹±ì— ì‹¤íŒ¨í–ˆì„ ê²½ìš°
    """
    
    # ë¶ˆí•„ìš”í•œ ê³µë°±, ê´„í˜¸, ìš”ì¼ ì •ë³´ ì œê±° (ì˜ˆ: '10-17 (ê¸ˆ)' -> '10-17')
    cleaned_text = re.sub(r'\s*\(.+\)', '', date_text).strip()
    
    # 1. ì›”-ì¼ í˜•ì‹ íŒŒì‹± ë¡œì§ ì¶”ê°€ (ëª©ë¡ í˜ì´ì§€ í˜•ì‹)
    month_day_pattern = r'(\d{1,2})[.-]\s*(\d{1,2})' 
    match_md = re.search(month_day_pattern, cleaned_text)
    
    if match_md:
        month, day = match_md.groups()
        current_year = datetime.now().year
        try:
            # ì—°ë„ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ í˜„ì¬ ì—°ë„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            return datetime(current_year, int(month), int(day))
        except ValueError:
            pass # ì˜ëª»ëœ ì›”/ì¼ì´ë©´ ë‹¤ìŒ íŒ¨í„´ ì‹œë„ (ë§¤ìš° ë“œë­„)

    
    # 2. ê¸°ì¡´ ì—°ë„ í¬í•¨ íŒ¨í„´ ì‹œë„
    date_patterns = [
        r'(\d{4})[.-](\d{1,2})[.-](\d{1,2})', # YYYY-MM-DD, YYYY.MM.DD
        r'(\d{4})/(\d{1,2})/(\d{1,2})',# YYYY/MM/DD
        r'(\d{1,2})[.-](\d{1,2})[.-](\d{4})',# MM-DD-YYYY, MM.DD.YYYY
    ]
    
    for pattern in date_patterns:
        match = re.search(pattern, cleaned_text)
        if match:
            groups = match.groups()
            if len(groups) == 3:
                try:
                    if len(groups[0]) == 4: # YYYY-MM-DD í˜•ì‹
                        year, month, day = groups
                    else: # MM-DD-YYYY í˜•ì‹
                        month, day, year = groups
                    
                    return datetime(int(year), int(month), int(day))
                except ValueError:
                    continue
    
    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ, ê¸°ë³¸ê°’ ë°˜í™˜ ëŒ€ì‹  ì˜¤ë¥˜ ë°œìƒ (ë””ë²„ê¹… ì§€ì›)
    raise ValueError(f"ë‚ ì§œ í…ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨: í˜•ì‹ '{date_text}'")

def is_date_in_range(date: datetime, start_date: str, end_date: str) -> bool:
    """
    ë‚ ì§œê°€ ì§€ì •ëœ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    
    Args:
        date (datetime): í™•ì¸í•  ë‚ ì§œ
        start_date (str): ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        end_date (str): ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
        
    Returns:
        bool: ë²”ìœ„ ë‚´ ì—¬ë¶€
    """
    try:
        start = datetime.strptime(start_date, "%Y-%m-%d")
        end = datetime.strptime(end_date, "%Y-%m-%d")
        return start <= date <= end
    except ValueError:
        return False

def crawl_all_data(driver, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ëª¨ë“  ë§¤ì¶œ/ë§¤ì… ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        driver: Selenium WebDriver ì¸ìŠ¤í„´ìŠ¤
        start_date (str): ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        end_date (str): ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
        
    Returns:
        pd.DataFrame: ì¶”ì¶œëœ ë°ì´í„°
            - ê¸°ë³¸ ì»¬ëŸ¼: ['ë‚ ì§œ', 'ë¬¸ì„œì œëª©', 'êµ¬ë¶„', 'ê³µê¸‰ê°€ì•¡']
            - ì¶”ê°€ ì»¬ëŸ¼: ['ê±°ë˜ì²˜ëª…', 'ë¶€ê°€ì„¸', 'í•©ê³„ê¸ˆì•¡', 'ë§í¬'] (ê°€ëŠ¥ ì‹œ)
    """
    try:
        logger.info("ğŸš€ ì „ì²´ ë°ì´í„° í¬ë¡¤ë§ ì‹œì‘ (run_full_crawling ì‚¬ìš©)")

        # í†µí•© í¬ë¡¤ë§ íŒŒì´í”„ë¼ì¸ ìˆ˜í–‰ (ëª©ë¡ â†’ íŒì—… ìƒì„¸ â†’ í†µí•©)
        all_data = run_full_crawling(driver, start_date, end_date)

        if not all_data:
            logger.warning("âš ï¸ ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame(columns=['ë‚ ì§œ', 'ë¬¸ì„œì œëª©', 'êµ¬ë¶„', 'ê³µê¸‰ê°€ì•¡'])

        # DataFrame ìƒì„± ë° í‘œì¤€ ì»¬ëŸ¼ ì •ë¦¬
        df = pd.DataFrame(all_data)

        # ë‚ ì§œ ì»¬ëŸ¼ í‘œì¤€í™”: 'ê¸°ì•ˆì¼' â†’ 'ë‚ ì§œ'
        if 'ê¸°ì•ˆì¼' in df.columns:
            df['ë‚ ì§œ'] = pd.to_datetime(df['ê¸°ì•ˆì¼'], errors='coerce')
        elif 'ë‚ ì§œ' in df.columns:
            df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce')
        else:
            # ë‚ ì§œ ì •ë³´ê°€ ì „í˜€ ì—†ëŠ” ê²½ìš° ë¹ˆ í”„ë ˆì„ ë°˜í™˜ (ì²˜ë¦¬ ëª¨ë“ˆ í˜¸í™˜ì„ ìœ„í•´)
            logger.warning("âš ï¸ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¹ˆ ë°ì´í„°í”„ë ˆì„ì„ ë°˜í™˜í•©ë‹ˆë‹¤")
            return pd.DataFrame(columns=['ë‚ ì§œ', 'ë¬¸ì„œì œëª©', 'êµ¬ë¶„', 'ê³µê¸‰ê°€ì•¡'])

        # êµ¬ë¶„ í‘œì¤€í™”: 'ë§¤ì¶œí’ˆì˜'/'ë§¤ì…í’ˆì˜' â†’ 'ë§¤ì¶œ'/'ë§¤ì…'
        if 'êµ¬ë¶„' in df.columns:
            df['êµ¬ë¶„'] = df['êµ¬ë¶„'].replace({'ë§¤ì¶œí’ˆì˜': 'ë§¤ì¶œ', 'ë§¤ì…í’ˆì˜': 'ë§¤ì…'})

        # í•„ìˆ˜ ê¸ˆì•¡ ì»¬ëŸ¼ ë³´ì •
        if 'ê³µê¸‰ê°€ì•¡' not in df.columns:
            df['ê³µê¸‰ê°€ì•¡'] = 0

        # í‘œì‹œ ì»¬ëŸ¼ êµ¬ì„± (ê°€ëŠ¥í•œ ê²½ìš° ì¶”ê°€ ì»¬ëŸ¼ í¬í•¨)
        base_columns = ['ë‚ ì§œ', 'ë¬¸ì„œì œëª©', 'êµ¬ë¶„', 'ê³µê¸‰ê°€ì•¡']
        extra_columns = [c for c in ['ê±°ë˜ì²˜ëª…', 'ë¶€ê°€ì„¸', 'í•©ê³„ê¸ˆì•¡', 'ë§í¬'] if c in df.columns]
        df = df[base_columns + extra_columns]

        # ì •ë ¬ ë° ì™„ë£Œ ë¡œê·¸
        df = df.sort_values('ë‚ ì§œ')
        logger.info(f"âœ… ì´ {len(df)}ê±´ì˜ ë°ì´í„° í¬ë¡¤ë§ ì™„ë£Œ")

        return df
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame(columns=['ë‚ ì§œ', 'ë¬¸ì„œì œëª©', 'êµ¬ë¶„', 'ê³µê¸‰ê°€ì•¡'])

